{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddca3899-0f70-4509-9995-31214f4c2fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "First, pip install pandas which we will be using to read and use our training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6b75ec02-2094-4800-b173-9126dbe79e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a virtual environment named 'venv'\n",
    "!python -m venv venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "40edd4b0-4185-4330-a393-e63453dc19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate the virtual environment (this may vary depending on your operating system)\n",
    "!source venv/bin/activate  # For Linux/macOS\n",
    "# OR\n",
    "#!venv\\Scripts\\activate  # For Windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9c2a8559-5745-401c-a15a-3b2a6b49cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1562e18-109a-4ecd-b585-dd30ffd6939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Next need to import libraries to setup and get the environment ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7f7a4b4b-8c2f-4acc-8962-625c687f9fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d32e6fdb-d499-42c0-aa03-0b1724349289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor, TabularDataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "32091d89-fbad-4da9-a04b-576f3eb3bc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: train_car.csv | Columns = 4 / 4 | Rows = 20999 -> 20999\n",
      "Loaded data from: test_car.csv | Columns = 3 / 3 | Rows = 1002 -> 1002\n"
     ]
    }
   ],
   "source": [
    "train_data = TabularDataset(data=\"train_car.csv\")\n",
    "test_data = TabularDataset(data=\"test_car.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c0d4e6d0-0f4b-43bc-a123-35ffd0b1bdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Miles</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chevrolet Trax</td>\n",
       "      <td>2018</td>\n",
       "      <td>41946</td>\n",
       "      <td>16990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GMC Terrain</td>\n",
       "      <td>2020</td>\n",
       "      <td>45328</td>\n",
       "      <td>23990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeep Wrangler</td>\n",
       "      <td>2012</td>\n",
       "      <td>81068</td>\n",
       "      <td>21590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jeep Renegade</td>\n",
       "      <td>2019</td>\n",
       "      <td>35372</td>\n",
       "      <td>21590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW X</td>\n",
       "      <td>20173</td>\n",
       "      <td>68992</td>\n",
       "      <td>22990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name   Year  Miles  Price\n",
       "0   Chevrolet Trax   2018  41946  16990\n",
       "1      GMC Terrain   2020  45328  23990\n",
       "2    Jeep Wrangler   2012  81068  21590\n",
       "3    Jeep Renegade   2019  35372  21590\n",
       "4            BMW X  20173  68992  22990"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "947e71a4-133c-484c-b013-16bc473bc700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Miles</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17021</th>\n",
       "      <td>Hyundai Elantra</td>\n",
       "      <td>2015</td>\n",
       "      <td>18824</td>\n",
       "      <td>18590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>MAZDA MX- Miata</td>\n",
       "      <td>20145</td>\n",
       "      <td>58700</td>\n",
       "      <td>19990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>Nissan Rogue</td>\n",
       "      <td>2020</td>\n",
       "      <td>60344</td>\n",
       "      <td>20106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>Mitsubishi Outlander Sport</td>\n",
       "      <td>2017</td>\n",
       "      <td>64442</td>\n",
       "      <td>15990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15517</th>\n",
       "      <td>Toyota Corolla</td>\n",
       "      <td>2014</td>\n",
       "      <td>84366</td>\n",
       "      <td>15590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name   Year  Miles  Price\n",
       "17021              Hyundai Elantra   2015  18824  18590\n",
       "3259               MAZDA MX- Miata  20145  58700  19990\n",
       "3833                  Nissan Rogue   2020  60344  20106\n",
       "3283    Mitsubishi Outlander Sport   2017  64442  15990\n",
       "15517               Toyota Corolla   2014  84366  15590"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sampling\n",
    "sample_size = 1000\n",
    "train_data_small = train_data.sample(n=sample_size, random_state=0)\n",
    "\n",
    "train_data_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "04f38980-de2f-40c4-838d-48b4abfe665a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"predict_smaller\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"predict_smaller\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.2.0: Fri Nov 11 02:03:51 PST 2022; root:xnu-8792.61.2~4/RELEASE_ARM64_T6000\n",
      "CPU Count:          8\n",
      "Memory Avail:       0.65 GB / 16.00 GB (4.0%)\n",
      "Disk Space Avail:   142.77 GB / 460.43 GB (31.0%)\n",
      "===================================================\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 3\n",
      "Label Column:       Price\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (71990, 11990, 20885.342, 6425.81618)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    662.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.08 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 2 | ['Year', 'Miles']\n",
      "\t\t('object', []) : 1 | ['Name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 1 | ['Name']\n",
      "\t\t('int', [])      : 2 | ['Year', 'Miles']\n",
      "\t0.1s = Fit runtime\n",
      "\t3 features in original data used to generate 3 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-35833233.9272\t = Validation score   (-mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-37472168.0271\t = Validation score   (-mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training... Skipping this model.\n",
      "\t\t'query-planning'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 98, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 21, in <module>\n",
      "    from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/compat.py\", line 145, in <module>\n",
      "    from dask.dataframe import DataFrame as dask_DataFrame\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 16, in <module>\n",
      "    if _dask_expr_enabled():\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 7, in _dask_expr_enabled\n",
      "    use_dask_expr = dask.config.get(\"dataframe.query-planning\")\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/config.py\", line 535, in get\n",
      "    Useful for getting kwarg defaults from Dask config.\n",
      "KeyError: 'query-planning'\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training... Skipping this model.\n",
      "\t\t'query-planning'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 98, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 21, in <module>\n",
      "    from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/compat.py\", line 145, in <module>\n",
      "    from dask.dataframe import DataFrame as dask_DataFrame\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 16, in <module>\n",
      "    if _dask_expr_enabled():\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 7, in _dask_expr_enabled\n",
      "    use_dask_expr = dask.config.get(\"dataframe.query-planning\")\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/config.py\", line 535, in get\n",
      "    Useful for getting kwarg defaults from Dask config.\n",
      "KeyError: 'query-planning'\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-28342763.3227\t = Validation score   (-mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-19743996.6459\t = Validation score   (-mean_squared_error)\n",
      "\t1.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-24065623.0304\t = Validation score   (-mean_squared_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-20000724.5156\t = Validation score   (-mean_squared_error)\n",
      "\t2.26s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-20459654.3118\t = Validation score   (-mean_squared_error)\n",
      "\t8.57s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-19304959.9537\t = Validation score   (-mean_squared_error)\n",
      "\t31.59s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training... Skipping this model.\n",
      "\t\t'query-planning'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 98, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 21, in <module>\n",
      "    from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/compat.py\", line 145, in <module>\n",
      "    from dask.dataframe import DataFrame as dask_DataFrame\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 16, in <module>\n",
      "    if _dask_expr_enabled():\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 7, in _dask_expr_enabled\n",
      "    use_dask_expr = dask.config.get(\"dataframe.query-planning\")\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/config.py\", line 535, in get\n",
      "    Useful for getting kwarg defaults from Dask config.\n",
      "KeyError: 'query-planning'\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 0.418, 'NeuralNetFastAI': 0.385, 'CatBoost': 0.198}\n",
      "\t-17305689.872\t = Validation score   (-mean_squared_error)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 45.5s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"predict_smaller\")\n"
     ]
    }
   ],
   "source": [
    "predict_smaller = TabularPredictor(label=\"Price\",\n",
    "                                   eval_metric=\"mean_squared_error\",\n",
    "                                   path=\"predict_smaller\"\n",
    "                                  ).fit(train_data_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c8bd0375-04dd-4e2a-a313-175e9043118c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-1.730569e+07</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.036233</td>\n",
       "      <td>35.299949</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.179486</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-1.930496e+07</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>31.590965</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>31.590965</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-1.974400e+07</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>1.267805</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>1.267805</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-2.000072e+07</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.021113</td>\n",
       "      <td>2.261693</td>\n",
       "      <td>0.021113</td>\n",
       "      <td>2.261693</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-2.045965e+07</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.009790</td>\n",
       "      <td>8.573687</td>\n",
       "      <td>0.009790</td>\n",
       "      <td>8.573687</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-2.406562e+07</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.040580</td>\n",
       "      <td>0.275830</td>\n",
       "      <td>0.040580</td>\n",
       "      <td>0.275830</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-2.834276e+07</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.039809</td>\n",
       "      <td>0.336203</td>\n",
       "      <td>0.039809</td>\n",
       "      <td>0.336203</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-3.583323e+07</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.015272</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.015272</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-3.747217e+07</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model     score_val         eval_metric  pred_time_val  \\\n",
       "0  WeightedEnsemble_L2 -1.730569e+07  mean_squared_error       0.036233   \n",
       "1       NeuralNetTorch -1.930496e+07  mean_squared_error       0.012946   \n",
       "2             CatBoost -1.974400e+07  mean_squared_error       0.001857   \n",
       "3      NeuralNetFastAI -2.000072e+07  mean_squared_error       0.021113   \n",
       "4              XGBoost -2.045965e+07  mean_squared_error       0.009790   \n",
       "5        ExtraTreesMSE -2.406562e+07  mean_squared_error       0.040580   \n",
       "6      RandomForestMSE -2.834276e+07  mean_squared_error       0.039809   \n",
       "7       KNeighborsUnif -3.583323e+07  mean_squared_error       0.015272   \n",
       "8       KNeighborsDist -3.747217e+07  mean_squared_error       0.016966   \n",
       "\n",
       "    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0  35.299949                0.000317           0.179486            2   \n",
       "1  31.590965                0.012946          31.590965            1   \n",
       "2   1.267805                0.001857           1.267805            1   \n",
       "3   2.261693                0.021113           2.261693            1   \n",
       "4   8.573687                0.009790           8.573687            1   \n",
       "5   0.275830                0.040580           0.275830            1   \n",
       "6   0.336203                0.039809           0.336203            1   \n",
       "7   0.016900                0.015272           0.016900            1   \n",
       "8   0.005337                0.016966           0.005337            1   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0       True          9  \n",
       "1       True          8  \n",
       "2       True          4  \n",
       "3       True          6  \n",
       "4       True          7  \n",
       "5       True          5  \n",
       "6       True          3  \n",
       "7       True          1  \n",
       "8       True          2  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_smaller.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1207f4c2-7a1a-4de7-9acd-3e055dc2a674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toyota Camry</td>\n",
       "      <td>2019</td>\n",
       "      <td>19796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kia Niro</td>\n",
       "      <td>2019</td>\n",
       "      <td>27189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyundai Elantra</td>\n",
       "      <td>2015</td>\n",
       "      <td>18824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Honda CR-V</td>\n",
       "      <td>2014</td>\n",
       "      <td>64396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ford Explorer</td>\n",
       "      <td>2015</td>\n",
       "      <td>105432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  Year   Miles\n",
       "0      Toyota Camry  2019   19796\n",
       "1          Kia Niro  2019   27189\n",
       "2   Hyundai Elantra  2015   18824\n",
       "3        Honda CR-V  2014   64396\n",
       "4     Ford Explorer  2015  105432"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cae5a704-36f1-43d0-9660-64d993b6953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some predicted results\n",
      "0    24084.322266\n",
      "1    24642.746094\n",
      "2    18707.195312\n",
      "3    19623.396484\n",
      "4    17540.898438\n",
      "5    16146.230469\n",
      "6    15496.059570\n",
      "7    21057.402344\n",
      "8    23260.027344\n",
      "9    17788.533203\n",
      "Name: Price, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "price_predict = predict_smaller.predict(test_data)\n",
    "print(f\"Some predicted results\") \n",
    "print(f\"{price_predict[0:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4458a956-cdee-4134-918b-9fda2a659d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name Price\n",
      "0      Toyota Camry   NaN\n",
      "1          Kia Niro   NaN\n",
      "2   Hyundai Elantra   NaN\n",
      "3        Honda CR-V   NaN\n",
      "4     Ford Explorer   NaN\n",
      "5     Nissan Sentra   NaN\n",
      "6   Hyundai Elantra   NaN\n",
      "7      Nissan Rogue   NaN\n",
      "8      Jeep Compass   NaN\n",
      "9   Chevrolet Cruze   NaN\n"
     ]
    }
   ],
   "source": [
    "output_data = pd.DataFrame(columns=[\"Name\",\"Price\"])\n",
    "output_data[\"Name\"] = test_data[\"Name\"].tolist()\n",
    "print(f\"{output_data[0:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "10b64e38-745c-4b93-aad7-f61389690a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name         Price\n",
      "0      Toyota Camry  24084.322266\n",
      "1          Kia Niro  24642.746094\n",
      "2   Hyundai Elantra  18707.195312\n",
      "3        Honda CR-V  19623.396484\n",
      "4     Ford Explorer  17540.898438\n",
      "5     Nissan Sentra  16146.230469\n",
      "6   Hyundai Elantra  15496.059570\n",
      "7      Nissan Rogue  21057.402344\n",
      "8      Jeep Compass  23260.027344\n",
      "9   Chevrolet Cruze  17788.533203\n"
     ]
    }
   ],
   "source": [
    "output_data[\"Price\"] = price_predict\n",
    "print(f\"{output_data[0:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c2bac3cb-f3e6-46e0-911e-4b9f7f44a20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: test_actual.csv | Columns = 4 / 4 | Rows = 1002 -> 1002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name  Year   Miles  Price\n",
      "0      Toyota Camry  2019   19796  24590\n",
      "1          Kia Niro  2019   27189  24990\n",
      "2   Hyundai Elantra  2015   18824  18590\n",
      "3        Honda CR-V  2014   64396  19590\n",
      "4     Ford Explorer  2015  105432  17590\n",
      "5     Nissan Sentra  2017   59223  14990\n",
      "6   Hyundai Elantra  2012   67040  13990\n",
      "7      Nissan Rogue  2018   34701  20990\n",
      "8      Jeep Compass  2019   21544  23590\n",
      "9   Chevrolet Cruze  2017   39976  17990\n"
     ]
    }
   ],
   "source": [
    "actual_data = TabularDataset(data=\"test_actual.csv\")\n",
    "print(f\"{actual_data[0:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bb8fe109-401c-4561-ad33-b44a6c914d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data.to_csv(\"output_smaller.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a1c087b3-3b85-47c2-a26d-337d2c52cd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240207_025511\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240207_025511\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.2.0: Fri Nov 11 02:03:51 PST 2022; root:xnu-8792.61.2~4/RELEASE_ARM64_T6000\n",
      "CPU Count:          8\n",
      "Memory Avail:       0.74 GB / 16.00 GB (4.6%)\n",
      "Disk Space Avail:   142.72 GB / 460.43 GB (31.0%)\n",
      "===================================================\n",
      "Train Data Rows:    20999\n",
      "Train Data Columns: 3\n",
      "Label Column:       Price\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\tFirst 10 (of 866) unique label values:  [16990, 23990, 21590, 22990, 18590, 17590, 17990, 16590, 14990, 15990]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 2 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 2 examples. AutoGluon will only keep 391 out of 866 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 2 examples that will be kept for training models: 0.9773798752321539\n",
      "Train Data Class Count: 391\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    758.38 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.71 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 2 | ['Year', 'Miles']\n",
      "\t\t('object', []) : 1 | ['Name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 1 | ['Name']\n",
      "\t\t('int', [])      : 2 | ['Year', 'Miles']\n",
      "\t0.1s = Fit runtime\n",
      "\t3 features in original data used to generate 3 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.35 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 18471, Val Rows: 2053\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 299.89s of the 299.88s of remaining time.\n",
      "\t-7598.396\t = Validation score   (-mean_squared_error)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 299.73s of the 299.73s of remaining time.\n",
      "\t-3717.9854\t = Validation score   (-mean_squared_error)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 299.61s of the 299.6s of remaining time.\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training... Skipping this model.\n",
      "\t\tException occured in `Recorder` when calling event `after_batch`:\n",
      "\t==:\n",
      "100096\n",
      "256\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 354, in _fit\n",
      "    self.model.fit_one_cycle(epochs, params[\"lr\"], cbs=callbacks)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/callback/schedule.py\", line 119, in fit_one_cycle\n",
      "    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 264, in fit\n",
      "    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 253, in _do_fit\n",
      "    self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 248, in _do_epoch\n",
      "    self._do_epoch_validate()\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 244, in _do_epoch_validate\n",
      "    with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 205, in all_batches\n",
      "    for o in enumerate(self.dl): self.one_batch(*o)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 235, in one_batch\n",
      "    self._with_events(self._do_one_batch, 'batch', CancelBatchException)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 201, in _with_events\n",
      "    self(f'after_{event_type}');  final()\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 172, in __call__\n",
      "    def __call__(self, event_name): L(event_name).map(self._call_one)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastcore/foundation.py\", line 156, in map\n",
      "    def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastcore/basics.py\", line 840, in map_ex\n",
      "    return list(res)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastcore/basics.py\", line 825, in __call__\n",
      "    return self.func(*fargs, **kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 176, in _call_one\n",
      "    for cb in self.cbs.sorted('order'): cb(event_name)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/callback/core.py\", line 62, in __call__\n",
      "    except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}', replace=True)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/callback/core.py\", line 60, in __call__\n",
      "    try: res = getcallable(self, event_name)()\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 560, in after_batch\n",
      "    for met in mets: met.accumulate(self.learn)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/learner.py\", line 482, in accumulate\n",
      "    self.total += learn.to_detach(self.func(learn.pred, *learn.yb))*bs\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/metrics.py\", line 278, in mse\n",
      "    return F.mse_loss(*flatten_check(inp,targ))\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastai/torch_core.py\", line 787, in flatten_check\n",
      "    test_eq(len(inp), len(targ))\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastcore/test.py\", line 37, in test_eq\n",
      "    test(a,b,equals, cname='==')\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/fastcore/test.py\", line 27, in test\n",
      "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
      "AssertionError: Exception occured in `Recorder` when calling event `after_batch`:\n",
      "\t==:\n",
      "100096\n",
      "256\n",
      "Fitting model: LightGBMXT ... Training model for up to 284.99s of the 284.99s of remaining time.\n",
      "\tWarning: Exception caused LightGBMXT to fail during training... Skipping this model.\n",
      "\t\t'query-planning'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 98, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 21, in <module>\n",
      "    from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/compat.py\", line 145, in <module>\n",
      "    from dask.dataframe import DataFrame as dask_DataFrame\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 16, in <module>\n",
      "    if _dask_expr_enabled():\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 7, in _dask_expr_enabled\n",
      "    use_dask_expr = dask.config.get(\"dataframe.query-planning\")\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/config.py\", line 535, in get\n",
      "    Useful for getting kwarg defaults from Dask config.\n",
      "KeyError: 'query-planning'\n",
      "Fitting model: LightGBM ... Training model for up to 284.88s of the 284.87s of remaining time.\n",
      "\tWarning: Exception caused LightGBM to fail during training... Skipping this model.\n",
      "\t\t'query-planning'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 98, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 21, in <module>\n",
      "    from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/lightgbm/compat.py\", line 145, in <module>\n",
      "    from dask.dataframe import DataFrame as dask_DataFrame\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 16, in <module>\n",
      "    if _dask_expr_enabled():\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/__init__.py\", line 7, in _dask_expr_enabled\n",
      "    use_dask_expr = dask.config.get(\"dataframe.query-planning\")\n",
      "  File \"/Users/paulantony/opt/anaconda3/lib/python3.9/site-packages/dask/config.py\", line 535, in get\n",
      "    Useful for getting kwarg defaults from Dask config.\n",
      "KeyError: 'query-planning'\n",
      "Fitting model: RandomForestGini ... Training model for up to 284.77s of the 284.77s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 4.815 GB out of 0.758 GB available memory (635.063%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=12.75 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestGini... Skipping this model.\n",
      "Fitting model: RandomForestEntr ... Training model for up to 284.67s of the 284.67s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 4.815 GB out of 0.756 GB available memory (637.221%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=12.79 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestEntr... Skipping this model.\n",
      "Fitting model: CatBoost ... Training model for up to 284.57s of the 284.57s of remaining time.\n",
      "Warning: Large model size may cause OOM error if training continues\n",
      "Warning: Early stopped model prior to optimal result to avoid OOM error. Please increase available memory to avoid subpar model quality.\n",
      "Available Memory: 682 MB, Estimated Model size: 1936 MB\n",
      "\tRan low on memory, early stopping on iteration 1.\n",
      "\t-7732.7282\t = Validation score   (-mean_squared_error)\n",
      "\t22.53s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 261.32s of the 261.32s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 4.815 GB out of 0.715 GB available memory (673.663%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=13.52 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesGini... Skipping this model.\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 261.09s of the 261.09s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 4.815 GB out of 0.730 GB available memory (659.468%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=13.24 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesEntr... Skipping this model.\n",
      "Fitting model: XGBoost ... Training model for up to 261.0s of the 261.0s of remaining time.\n",
      "\t-5005.036\t = Validation score   (-mean_squared_error)\n",
      "\t263.69s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.89s of the -3.51s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.562, 'XGBoost': 0.375, 'KNeighborsDist': 0.062}\n",
      "\t-2499.058\t = Validation score   (-mean_squared_error)\n",
      "\t4.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 307.92s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240207_025511\")\n"
     ]
    }
   ],
   "source": [
    "#2 create model\n",
    "predictor = TabularPredictor(label=\"Price\",\n",
    "                             eval_metric=\"mean_squared_error\",\n",
    "                             path=\"predictor\"\n",
    "                            ).fit(train_data=train_data,\n",
    "                                 time_limit=5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fd7ff06d-8a42-447e-8aa0-535933830c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name  Price\n",
      "0      Toyota Camry  24590\n",
      "1          Kia Niro  24990\n",
      "2   Hyundai Elantra  18590\n",
      "3        Honda CR-V  19590\n",
      "4     Ford Explorer  17590\n",
      "5     Nissan Sentra  14990\n",
      "6   Hyundai Elantra  13990\n",
      "7      Nissan Rogue  20990\n",
      "8      Jeep Compass  23590\n",
      "9   Chevrolet Cruze  17990\n"
     ]
    }
   ],
   "source": [
    "#3 predict using predictor model\n",
    "final_prediction = predictor.predict(test_data)\n",
    "\n",
    "#4 output save\n",
    "output_data = pd.DataFrame(columns=[\"Name\",\"Price\"])\n",
    "output_data[\"Name\"] = test_data[\"Name\"].tolist()\n",
    "output_data[\"Price\"] = final_prediction\n",
    "\n",
    "print(f\"{output_data[0:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0cc69409-04de-4310-a0ef-0e5141506e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: test_actual.csv | Columns = 4 / 4 | Rows = 1002 -> 1002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name  Year   Miles  Price\n",
      "0      Toyota Camry  2019   19796  24590\n",
      "1          Kia Niro  2019   27189  24990\n",
      "2   Hyundai Elantra  2015   18824  18590\n",
      "3        Honda CR-V  2014   64396  19590\n",
      "4     Ford Explorer  2015  105432  17590\n",
      "5     Nissan Sentra  2017   59223  14990\n",
      "6   Hyundai Elantra  2012   67040  13990\n",
      "7      Nissan Rogue  2018   34701  20990\n",
      "8      Jeep Compass  2019   21544  23590\n",
      "9   Chevrolet Cruze  2017   39976  17990\n"
     ]
    }
   ],
   "source": [
    "actual_data = TabularDataset(data=\"test_actual.csv\")\n",
    "print(f\"{actual_data[0:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "36961900-7f41-4ffa-8224-32958d91b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data.to_csv(\"output.csv\", sep='\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "95cb392f-0afa-48e2-b664-55bb40fec60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 3 features using 1000 rows with 5 shuffle sets...\n",
      "\t24.17s\t= Expected runtime (4.83s per shuffle set)\n",
      "\t7.57s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>2.328821e+07</td>\n",
       "      <td>7.049924e+05</td>\n",
       "      <td>1.006571e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>2.473979e+07</td>\n",
       "      <td>2.183662e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miles</th>\n",
       "      <td>1.846711e+07</td>\n",
       "      <td>1.135868e+06</td>\n",
       "      <td>1.708871e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>2.080588e+07</td>\n",
       "      <td>1.612834e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>7.906518e+06</td>\n",
       "      <td>4.785839e+05</td>\n",
       "      <td>1.603075e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>8.891929e+06</td>\n",
       "      <td>6.921107e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance        stddev       p_value  n      p99_high       p99_low\n",
       "Name   2.328821e+07  7.049924e+05  1.006571e-07  5  2.473979e+07  2.183662e+07\n",
       "Miles  1.846711e+07  1.135868e+06  1.708871e-06  5  2.080588e+07  1.612834e+07\n",
       "Year   7.906518e+06  4.785839e+05  1.603075e-06  5  8.891929e+06  6.921107e+06"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_smaller.feature_importance(train_data_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a8fa3a5e-25b6-47a0-84cf-879ee52097b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 3 features using 5000 rows with 5 shuffle sets...\n",
      "\t36.68s\t= Expected runtime (7.34s per shuffle set)\n",
      "\t25.72s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Miles</th>\n",
       "      <td>10432.54276</td>\n",
       "      <td>122.123786</td>\n",
       "      <td>2.252902e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>10683.997323</td>\n",
       "      <td>10181.088197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>6450.96520</td>\n",
       "      <td>86.952688</td>\n",
       "      <td>3.960129e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>6630.001987</td>\n",
       "      <td>6271.928413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>2741.22848</td>\n",
       "      <td>351.781874</td>\n",
       "      <td>3.184326e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>3465.552220</td>\n",
       "      <td>2016.904740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        importance      stddev       p_value  n      p99_high       p99_low\n",
       "Miles  10432.54276  122.123786  2.252902e-09  5  10683.997323  10181.088197\n",
       "Year    6450.96520   86.952688  3.960129e-09  5   6630.001987   6271.928413\n",
       "Name    2741.22848  351.781874  3.184326e-05  5   3465.552220   2016.904740"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421f58c-9cbc-44aa-8472-cdd526560427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
